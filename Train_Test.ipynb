{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26120e64-64bc-4b39-9c0a-ed076295ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eae19d-043a-4044-88c0-f579e0c6bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319fcaec-2940-44d6-b4a5-22dbc73ea436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867cfe2-7ac1-4a00-8b3e-b4d187827895",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array=cv2.imread(\"Training/2/Training_135069.jpg\")\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3429aba-4997-4d6b-8057-fd0f7ae9479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f851c7-f093-4534-ae26-153fb419568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datadir = \"Training/\"\n",
    "classes = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267240d7-745b-4e6e-a202-6b3be5723c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in classes:\n",
    "    path=os.path.join(Datadir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=cv2.imread(os.path.join(path,img))\n",
    "        plt.imshow(cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a554ef7-2bb3-405b-a233-697ac6a71f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "new_array = cv2.resize(img_array, (img_size,img_size))\n",
    "plt.imshow(cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb0f538-2e70-43f7-acb7-d74a409df329",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ecea89-ea2c-479b-b834-3350fdd313cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_Data = []\n",
    "def create_training_data():\n",
    "    for category in classes:\n",
    "        path=os.path.join(Datadir, category)\n",
    "        class_num = classes.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                new_array=cv2.resize(img_array,(img_size,img_size))\n",
    "                training_Data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac719802-dba6-413a-a2f7-27c63b7a413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()\n",
    "print(len(training_Data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8de79-2932-41bc-b5e2-e3843cffc58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0eff8-9715-4413-ac05-0d63b1a5a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_Data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, img_size, img_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d590b-9577-4ebd-8c7c-150f467b5289",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2150ddd-8dff-4595-81d2-c65d2c149d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eafb0c-1720-40cc-86b6-77768f4a8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suppose X is your original uint8 array\n",
    "X= np.array([img.astype('float32')/255.0 for img in X], dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e74aa-c53d-4494-ba2d-c3d627f378dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dea7fa-c784-4d86-8ef0-66e32e61db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.applications.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b870c-d971-4d53-8553-99a94100f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba126b-61c2-4061-b1d7-5f19303ed46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input = model.layers[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91bfc3-6695-4efe-a0d0-40561b7d886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output=model.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9fa3fe-6253-4dfc-beb6-8edb2d508ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dacf8f4-dbfe-40e2-9ed9-eac13509e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797a943-04e3-487b-a7f8-974794438d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = layers.Dense(128)(base_output)\n",
    "final_output = layers.Activation('relu')(final_output)\n",
    "final_output = layers.Dense(64)(final_output)\n",
    "final_output = layers.Activation('relu')(final_output)\n",
    "final_output = layers.Dense(7,activation='softmax')(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bed57-375d-449e-969b-791f665a95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d178725-d749-48c3-8508-281499697cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.Model(inputs = base_input, outputs = final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38e867-f734-4bbb-a7a2-f346e0496470",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60f80b-fbe1-41b7-9c25-4bcec5916d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = \"adam\" , metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461ee28-f433-4721-97bd-e5694635c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model.fit(X,Y,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842821b6-b3a2-471d-8520-3398ba7aecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = datagen.flow(X, Y, batch_size=batch_size)\n",
    "\n",
    "new_model.fit(train_generator, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4bc687-6264-4c47-a5d1-3fc16f13e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save('final_Model-95p07.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('25EP.h5')\n",
    "\n",
    "print(\"Input shape:\", model.input_shape)\n",
    "print(\"Output shape:\", model.output_shape)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbc8e9-ede1-451a-aa05-c741ff39cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(\"11.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8b9bc-22dd-4aa8-bd3d-fac27d3b7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4916a6-2ed7-4d59-9491-e1e17fad0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a5b4cd-86ac-4546-8479-e2b795001d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13f328-5468-45a5-be31-795dc24b087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4194060-e3fd-47f5-ba1d-19616d8e35e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "for x,y,w,h in faces:\n",
    "    roi_gray = gray[y:y+h,x:x+w]\n",
    "    roi_color = frame[y:y+h,x:x+w]\n",
    "    cv2.rectangle(frame,(x,y), (x+w , y+h), (255,0,0),2)\n",
    "    faces= faceCascade.detectMultiScale(roi_gray)\n",
    "    if len(faces)==0:\n",
    "        print(\"Face not detected\")\n",
    "    else:\n",
    "        for(ex,ey,ew,eh)in faces:\n",
    "            face_roi = roi_color[ey: ey+eh, ex:ex + ew]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45152af1-db2f-475c-b0fc-87072204f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ba89e-4dc2-4183-a28b-d4cd0d7fb868",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c219d65-6922-4aa1-ad0c-d73d8cb46732",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image = cv2.resize(face_roi, (224,224))\n",
    "final_image = np.expand_dims(final_image,axis = 0)\n",
    "final_image=final_image/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313390b-a6f3-442a-98e1-9e3c31df55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Load the model\n",
    "model = keras.models.load_model(\"20EP.h5\")\n",
    "Predicitions=model.predict(final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1d039-2ef8-40bb-a60c-1ec9d4e35f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicitions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa14674-dc26-4a21-8bac-087b98bcf897",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(Predicitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe8164-a166-43af-b2ea-c61c6f96ffe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e1ee1-c372-4c58-84cc-642e2698bea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6247e-e78f-4ed3-97f8-e2be7f61f9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c54935-0c78-4a0f-acb2-c463e7572b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1b372-6a5a-435f-a4fb-77a03f0aeb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87acd993-115a-474b-8449-723efdad3616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826fd9d-fe87-42ed-8ad6-af0003f52f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b536c0-42bf-4f9f-8cd7-db424aa95b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead4783b-c752-46aa-b6df-f114c77a99a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b984d04-9cca-4f06-890b-41fde0af17a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c36a5-a537-4fe7-a18c-172718e6c95c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d769b-35c1-4ba6-80cd-d0c4ff2378c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404ac36-c2b6-4145-896c-74051fa10852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
